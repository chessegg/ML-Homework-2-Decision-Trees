{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decision_tree.py<br>\n",
    "---------<br>\n",
    "Licensing Information:  You are free to use or extend these projects for<br>\n",
    "personal and educational purposes provided that (1) you do not distribute<br>\n",
    "or publish solutions, (2) you retain this notice, and (3) you provide clear<br>\n",
    "attribution to UT Dallas, including a link to http://cs.utdallas.edu.<br>\n",
    "<br>\n",
    "This file is part of Homework for CS6375: Machine Learning.<br>\n",
    "Gautam Kunapuli (gautam.kunapuli@utdallas.edu)<br>\n",
    "Sriraam Natarajan (sriraam.natarajan@utdallas.edu),<br>\n",
    "Anjum Chida (anjum.chida@utdallas.edu)<br>\n",
    "<br>\n",
    "<br>\n",
    "INSTRUCTIONS:<br>\n",
    "------------<br>\n",
    "1. This file contains a skeleton for implementing the ID3 algorithm for<br>\n",
    "Decision Trees. Insert your code into the various functions that have the<br>\n",
    "comment \"INSERT YOUR CODE HERE\".<br>\n",
    "<br>\n",
    "2. Do NOT modify the classes or functions that have the comment \"DO NOT<br>\n",
    "MODIFY THIS FUNCTION\".<br>\n",
    "<br>\n",
    "3. Do not modify the function headers for ANY of the functions.<br>\n",
    "<br>\n",
    "4. You may add any other helper functions you feel you may need to print,<br>\n",
    "visualize, test, or save the data and results. However, you MAY NOT utilize<br>\n",
    "the package scikit-learn OR ANY OTHER machine learning package in THIS file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import graphviz\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(x):\n",
    "    \"\"\"\n",
    "    Partition the column vector x into subsets indexed by its unique values (v1, ... vk)\n",
    "    Returns a dictionary of the form\n",
    "    { v1: indices of x == v1,\n",
    "      v2: indices of x == v2,\n",
    "      ...\n",
    "      vk: indices of x == vk }, where [v1, ... vk] are all the unique values in the vector z.\n",
    "    \"\"\"\n",
    "\n",
    "    indices = {}\n",
    "    for value in range(len(x)):\n",
    "        indices[x[value]] = indices.get(x[value], []) + [value]\n",
    "    return indices\n",
    "    raise Exception('Function not yet implemented!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [0, 3], 5: [1, 5, 7], 3: [2, 6, 8], 7: [4], 2: [9]}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition([1,5,3,1,7,5,3,5,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    \"\"\"\n",
    "    Compute the entropy of a vector y by considering the counts of the unique values (v1, ... vk), in z\n",
    "    Returns the entropy of z: H(z) = p(z=v1) log2(p(z=v1)) + ... + p(z=vk) log2(p(z=vk))\n",
    "    \"\"\"\n",
    "\n",
    "    values, count = np.unique(y, return_counts=\"True\")\n",
    "    h = 0\n",
    "    for c in count:\n",
    "        h += ((c/len(y))* math.log(c/len(y), 2))\n",
    "    return -h\n",
    "    raise Exception('Function not yet implemented!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182958340544896"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy([1,0,1,1,0,1,0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(x, y):\n",
    "    \"\"\"\n",
    "    Compute the mutual information between a data column (x) and the labels (y). The data column is a single attribute\n",
    "    over all the examples (n x 1). Mutual information is the difference between the entropy BEFORE the split set, and\n",
    "    the weighted-average entropy of EACH possible split.\n",
    "    Returns the mutual information: I(x, y) = H(y) - H(y | x)\n",
    "    \"\"\"\n",
    "\n",
    "    e_y = entropy(y)\n",
    "    d = {}\n",
    "    values, count = np.unique(x, return_counts=\"True\")\n",
    "    for v in values:\n",
    "        new_y1 = []\n",
    "        new_y2 = []\n",
    "        for i in range(len(y)):\n",
    "            if (x[i] == v):\n",
    "                new_y1.append(y[i])\n",
    "            else:\n",
    "                new_y2.append(y[i])\n",
    "        d[v] = e_y - (((len(new_y1)/len(y))*entropy(new_y1)) + ((len(new_y2)/len(y))*entropy(new_y2)))\n",
    "    return d\n",
    "    raise Exception('Function not yet implemented!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain_specified_value(x, v, y):\n",
    "    d = mutual_information(x,y)\n",
    "    return d.get(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.0, 'b': 0.034851554559677034, 'c': 0.034851554559677034}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = ['a','a','b','c','a','b','c','a','b','c']\n",
    "m2 = [1,0,1,0,0,0,1,1,1,0]\n",
    "mutual_information(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034851554559677034"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = ['a','a','b','c','a','b','c','a','b','c']\n",
    "m2 = [1,0,1,0,0,0,1,1,1,0]\n",
    "info_gain_specified_value(m1, 'b', m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(x, y, attribute_value_pairs=None, depth=0, max_depth=5):\n",
    "    \"\"\"\n",
    "    Implements the classical ID3 algorithm given training data (x), training labels (y) and an array of\n",
    "    attribute-value pairs to consider. This is a recursive algorithm that depends on three termination conditions\n",
    "        1. If the entire set of labels (y) is pure (all y = only 0 or only 1), then return that label\n",
    "        2. If the set of attribute-value pairs is empty (there is nothing to split on), then return the most common\n",
    "           value of y (majority label)\n",
    "        3. If the max_depth is reached (pre-pruning bias), then return the most common value of y (majority label)\n",
    "    Otherwise the algorithm selects the next best attribute-value pair using INFORMATION GAIN as the splitting criterion\n",
    "    and partitions the data set based on the values of that attribute before the next recursive call to ID3.\n",
    "    The tree we learn is a BINARY tree, which means that every node has only two branches. The splitting criterion has\n",
    "    to be chosen from among all possible attribute-value pairs. That is, for a problem with two features/attributes x1\n",
    "    (taking values a, b, c) and x2 (taking values d, e), the initial attribute value pair list is a list of all pairs of\n",
    "    attributes with their corresponding values:\n",
    "    [(x1, a),\n",
    "     (x1, b),\n",
    "     (x1, c),\n",
    "     (x2, d),\n",
    "     (x2, e)]\n",
    "     If we select (x2, d) as the best attribute-value pair, then the new decision node becomes: [ (x2 == d)? ] and\n",
    "     the attribute-value pair (x2, d) is removed from the list of attribute_value_pairs.\n",
    "    The tree is stored as a nested dictionary, where each entry is of the form\n",
    "                    (attribute_index, attribute_value, True/False): subtree\n",
    "    * The (attribute_index, attribute_value) determines the splitting criterion of the current node. For example, (4, 2)\n",
    "    indicates that we test if (x4 == 2) at the current node.\n",
    "    * The subtree itself can be nested dictionary, or a single label (leaf node).\n",
    "    * Leaf nodes are (majority) class labels\n",
    "    Returns a decision tree represented as a nested dictionary, for example\n",
    "    {(4, 1, False):\n",
    "        {(0, 1, False):\n",
    "            {(1, 1, False): 1,\n",
    "             (1, 1, True): 0},\n",
    "         (0, 1, True):\n",
    "            {(1, 1, False): 0,\n",
    "             (1, 1, True): 1}},\n",
    "     (4, 1, True): 1}\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    #populate attribute_value_pairs\n",
    "    if depth == 0:\n",
    "        attribute_value_pairs = []\n",
    "        for attr in range(len(x[0])):\n",
    "            for val in np.unique(np.transpose(x[:,attr])):\n",
    "                pair = (attr, val)\n",
    "                attribute_value_pairs.append(pair)\n",
    "    \n",
    "    #checks if entire set of labels(y) is pure\n",
    "    if len(np.unique(y)) == 1:\n",
    "        return y[0]\n",
    "    \n",
    "    #checks if attr val pairs are empty, or if at max depth. In both cases, return majority label\n",
    "    if (not attribute_value_pairs) or depth == max_depth or len(x) == 0:\n",
    "        values, counts = np.unique(y, return_counts = \"True\")\n",
    "        if counts.size == 0:\n",
    "            return 0\n",
    "        index_max = np.argmax(counts)\n",
    "        return values[index_max]\n",
    "    \n",
    "    d = {}\n",
    "    max_ig = -1\n",
    "    dec_node = (-1,-1)\n",
    "\n",
    "    for pair in attribute_value_pairs:\n",
    "        attr_vec = np.transpose(x)[pair[0]]\n",
    "        info_gain = mutual_information(attr_vec, y).get(pair[1])\n",
    "        if info_gain is None:\n",
    "            continue\n",
    "        if info_gain > max_ig:\n",
    "            max_ig = info_gain\n",
    "            dec_node = pair\n",
    "    if dec_node == (-1,-1):\n",
    "        values, counts = np.unique(y, return_counts = \"True\")\n",
    "        return values[np.argmax(counts)]\n",
    "    else:\n",
    "        attribute_value_pairs.remove(dec_node)\n",
    "    \n",
    "    x_new1 = []\n",
    "    x_new2 = []\n",
    "    y_new1 = []\n",
    "    y_new2 = []\n",
    "    for i in range(len(x)):\n",
    "        if x[i][dec_node[0]] == dec_node[1]:\n",
    "            x_new1.append(x[i])\n",
    "            y_new1.append(y[i])\n",
    "        else:\n",
    "            x_new2.append(x[i])\n",
    "            y_new2.append(y[i])\n",
    "            \n",
    "    \n",
    "    d[(dec_node[0], dec_node[1], False)] = id3(x_new2, y_new2, attribute_value_pairs, depth+1, max_depth)\n",
    "    d[(dec_node[0], dec_node[1], True)] = id3(x_new1, y_new1, attribute_value_pairs, depth+1, max_depth)\n",
    "    return d\n",
    "        \n",
    "    raise Exception('Function not yet implemented!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2, 0, False): {(0, 1, False): 1,\n",
       "  (0, 1, True): {(1, 3, False): 0, (1, 3, True): 1}},\n",
       " (2, 0, True): 0}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[0,0,0],[1,2,2],[2,0,1],[0,1,1],[2,2,2],[1,0,1],[1,1,0],[3,2,1],[1,3,3],[0,0,1]]\n",
    "y = [0,0,1,1,1,0,0,1,1,1]\n",
    "id3(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_example(x, tree):\n",
    "    \"\"\"\n",
    "    Predicts the classification label for a single example x using tree by recursively descending the tree until\n",
    "    a label/leaf node is reached.\n",
    "    Returns the predicted label of x according to tree\n",
    "    \"\"\"\n",
    "\n",
    "    root = list(tree.keys())\n",
    "    attr = root[0][0]\n",
    "    val = root[0][1]\n",
    "    if x[attr] == val:\n",
    "        subTree = tree.get((attr, val, True))\n",
    "    else:\n",
    "        subTree = tree.get((attr, val, False))\n",
    "    \n",
    "    if subTree == 0 or subTree == 1:\n",
    "        return subTree\n",
    "    else:\n",
    "        return predict_example(x, subTree)\n",
    "        \n",
    "    raise Exception('Function not yet implemented!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[0,0,0],[1,2,2],[2,0,1],[0,1,1],[2,2,2],[1,0,1],[1,1,0],[3,2,1],[1,3,3],[0,0,1]]\n",
    "y = [0,0,1,1,1,0,0,1,1,1]\n",
    "predict_example([1,2,1],id3(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the average error between the true labels (y_true) and the predicted labels (y_pred)\n",
    "    Returns the error = (1/n) * sum(y_true != y_pred)\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(y_true)\n",
    "    sum = 0\n",
    "    for i in range(n):\n",
    "        if (y_true[i] != y_pred[i]):\n",
    "            sum += 1\n",
    "            \n",
    "    return (1/n) * sum\n",
    "    raise Exception('Function not yet implemented!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(tree, depth=0):\n",
    "    \"\"\"\n",
    "    Pretty prints the decision tree to the console. Use print(tree) to print the raw nested dictionary representation\n",
    "    DO NOT MODIFY THIS FUNCTION!\n",
    "    \"\"\"\n",
    "    if depth == 0:\n",
    "        print('TREE')\n",
    "    for index, split_criterion in enumerate(tree):\n",
    "        sub_trees = tree[split_criterion]\n",
    "\n",
    "        # Print the current node: split criterion\n",
    "        print('|\\t' * depth, end='')\n",
    "        print('+-- [SPLIT: x{0} = {1} {2}]'.format(split_criterion[0], split_criterion[1], split_criterion[2]))\n",
    "\n",
    "        # Print the children\n",
    "        if type(sub_trees) is dict:\n",
    "            pretty_print(sub_trees, depth + 1)\n",
    "        else:\n",
    "            print('|\\t' * (depth + 1), end='')\n",
    "            print('+-- [LABEL = {0}]'.format(sub_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_dot_file(dot_string, save_file, image_format='png'):\n",
    "    \"\"\"\n",
    "    Uses GraphViz to render a dot file. The dot file can be generated using\n",
    "        * sklearn.tree.export_graphviz()' for decision trees produced by scikit-learn\n",
    "        * to_graphviz() (function is in this file) for decision trees produced by  your code.\n",
    "    DO NOT MODIFY THIS FUNCTION!\n",
    "    \"\"\"\n",
    "    if type(dot_string).__name__ != 'str':\n",
    "        raise TypeError('visualize() requires a string representation of a decision tree.\\nUse tree.export_graphviz()'\n",
    "                        'for decision trees produced by scikit-learn and to_graphviz() for decision trees produced by'\n",
    "                        'your code.\\n')\n",
    "\n",
    "    # Set path to your GraphViz executable here\n",
    "    os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "    graph = graphviz.Source(dot_string)\n",
    "    graph.format = image_format\n",
    "    graph.render(save_file, view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_graphviz(tree, dot_string='', uid=-1, depth=0):\n",
    "    \"\"\"\n",
    "    Converts a tree to DOT format for use with visualize/GraphViz\n",
    "    DO NOT MODIFY THIS FUNCTION!\n",
    "    \"\"\"\n",
    "    uid += 1       # Running index of node ids across recursion\n",
    "    node_id = uid  # Node id of this node\n",
    "    if depth == 0:\n",
    "        dot_string += 'digraph TREE {\\n'\n",
    "    for split_criterion in tree:\n",
    "        sub_trees = tree[split_criterion]\n",
    "        attribute_index = split_criterion[0]\n",
    "        attribute_value = split_criterion[1]\n",
    "        split_decision = split_criterion[2]\n",
    "        if not split_decision:\n",
    "            # Alphabetically, False comes first\n",
    "            dot_string += '    node{0} [label=\"x{1} = {2}?\"];\\n'.format(node_id, attribute_index, attribute_value)\n",
    "        if type(sub_trees) is dict:\n",
    "            if not split_decision:\n",
    "                dot_string, right_child, uid = to_graphviz(sub_trees, dot_string=dot_string, uid=uid, depth=depth + 1)\n",
    "                dot_string += '    node{0} -> node{1} [label=\"False\"];\\n'.format(node_id, right_child)\n",
    "            else:\n",
    "                dot_string, left_child, uid = to_graphviz(sub_trees, dot_string=dot_string, uid=uid, depth=depth + 1)\n",
    "                dot_string += '    node{0} -> node{1} [label=\"True\"];\\n'.format(node_id, left_child)\n",
    "        else:\n",
    "            uid += 1\n",
    "            dot_string += '    node{0} [label=\"y = {1}\"];\\n'.format(uid, sub_trees)\n",
    "            if not split_decision:\n",
    "                dot_string += '    node{0} -> node{1} [label=\"False\"];\\n'.format(node_id, uid)\n",
    "            else:\n",
    "                dot_string += '    node{0} -> node{1} [label=\"True\"];\\n'.format(node_id, uid)\n",
    "    if depth == 0:\n",
    "        dot_string += '}\\n'\n",
    "        return dot_string\n",
    "    else:\n",
    "        return dot_string, node_id, uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREE\n",
      "+-- [SPLIT: x4 = 1 False]\n",
      "|\t+-- [SPLIT: x0 = 1 False]\n",
      "|\t|\t+-- [SPLIT: x1 = 1 False]\n",
      "|\t|\t|\t+-- [LABEL = 1]\n",
      "|\t|\t+-- [SPLIT: x1 = 1 True]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "|\t+-- [SPLIT: x0 = 1 True]\n",
      "|\t|\t+-- [SPLIT: x1 = 3 False]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "|\t|\t+-- [SPLIT: x1 = 3 True]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "+-- [SPLIT: x4 = 1 True]\n",
      "|\t+-- [LABEL = 1]\n",
      "Test Error = 25.00%.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Load the training data\n",
    "    M = np.genfromtxt('./monks-1.train', missing_values=0, skip_header=0, delimiter=',', dtype=int)\n",
    "    ytrn = M[:, 0]\n",
    "    Xtrn = M[:, 1:]\n",
    "\n",
    "    # Load the test data\n",
    "    M = np.genfromtxt('./monks-1.test', missing_values=0, skip_header=0, delimiter=',', dtype=int)\n",
    "    ytst = M[:, 0]\n",
    "    Xtst = M[:, 1:]\n",
    "\n",
    "    # Learn a decision tree of depth 3\n",
    "    decision_tree = id3(Xtrn, ytrn, max_depth=3)\n",
    "\n",
    "    # Pretty print it to console\n",
    "    pretty_print(decision_tree)\n",
    "\n",
    "    # Visualize the tree and save it as a PNG image\n",
    "    dot_str = to_graphviz(decision_tree)\n",
    "    render_dot_file(dot_str, './my_learned_tree')\n",
    "\n",
    "    # Compute the test error\n",
    "    y_pred = [predict_example(x, decision_tree) for x in Xtst]\n",
    "    tst_err = compute_error(ytst, y_pred)\n",
    "\n",
    "    print('Test Error = {0:4.2f}%.'.format(tst_err * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
